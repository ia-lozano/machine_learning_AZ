{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"37puETfgRzzg"},"source":["# Data Preprocessing Tools"]},{"cell_type":"markdown","metadata":{"id":"EoRP98MpR-qj"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"N-qiINBQSK2g"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importing Data set from Google Drive"],"metadata":{"id":"mGPKfNl4VTiN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('/content/drive/My Drive/DataAnalisys/MLAZ/P1_Data_Preprocessing/Section2/Python')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWacPYQIVaAI","executionInfo":{"status":"ok","timestamp":1724273135771,"user_tz":360,"elapsed":22914,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"cac64260-3020-4cef-ecec-646e20e3966a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"RopL7tUZSQkT"},"source":["## Importing the dataset"]},{"cell_type":"code","metadata":{"id":"WwEPNDWySTKm"},"source":["# This will create a Pandas Data Frame\n","dataset = pd.read_csv('Data.csv')\n","\n","# iloc selects the Data Frame columns by index\n","X = dataset.iloc[:, :-1].values\n","y = dataset.iloc[:, -1].values\n","\n","## IMPORTANT NOTES\n","# If the delimiter is not the default (,) in the CSV file, pd.read_csv() must take a second argument\n","# specifying the delimiter, for instance: pd.read_csv('file.csv', delimiter = ';')\n","\n","# NOTE that you can separate the target variable from the features\n","# this other way:\n","# X = dataset.drop('column_name', axis = 1)\n","# y = df['column_name']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCsz2yCebe1R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273140852,"user_tz":360,"elapsed":153,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"1eaa5079-d94a-4a74-9cea-bb2aad1016b7"},"source":["print(X)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"code","metadata":{"id":"eYrOQ43XcJR3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273142566,"user_tz":360,"elapsed":150,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"48bfbe34-8108-490d-fd83-3e0cda080a7b"},"source":["print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}]},{"cell_type":"markdown","metadata":{"id":"nhfKXNxlSabC"},"source":["## Taking care of missing data"]},{"cell_type":"code","metadata":{"id":"c93k7ipkSexq","executionInfo":{"status":"ok","timestamp":1724273144226,"user_tz":360,"elapsed":662,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"728b8a4f-b47e-4960-e602-f772c7b7f24c"},"source":["from sklearn.impute import SimpleImputer\n","\n","# Identifying missing data\n","missing_data = dataset.isnull().sum()\n","print('Missing data \\n', missing_data)\n","\n","# Replacing all the missing values (np.nan) with the average values\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","\n","# Replacing the values only in numerical columns, this will apply the 'strategy'\n","# defined in the SimpleImputer method\n","imputer.fit(X[:, 1:3])\n","\n","# Return and save the results obtained with the fit() method\n","X[:, 1:3] = imputer.transform(X[:, 1:3])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Missing data \n"," Country      0\n","Age          1\n","Salary       1\n","Purchased    0\n","dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"3UgLdMS_bjq_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273145883,"user_tz":360,"elapsed":153,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"c6213607-5134-4438-f50e-193d49a921a1"},"source":["print(X)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CriG6VzVSjcK"},"source":["## Encoding categorical data"]},{"cell_type":"markdown","metadata":{"id":"AhSpdQWeSsFh"},"source":["### Encoding the Independent Variable"]},{"cell_type":"code","metadata":{"id":"5hwuVddlSwVi"},"source":["# To change strings into values, for instance from 'yes' to 1 and 'no' to 0\n","# We need to encode the data.\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# ColumnTransformer takes 2 arguments, first one transformers = where we specify what kind of transformation we need\n","# transformers = ([(kind of transformation, class to procedure the encoding(), [index of columns to transform])])\n","# NOTE that the 3rd argument can contain a variable (or a list) holding the column header names (ex. ['Country', ])\n","# and remainder in this case indicates that we need to keet the columns not undergoing transformation\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","\n","# Updating X\n","X = np.array(ct.fit_transform(X))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f7QspewyeBfx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273149246,"user_tz":360,"elapsed":155,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"76b07f0b-43a0-427f-9feb-6f0401f99d95"},"source":["print(X)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"DXh8oVSITIc6"},"source":["### Encoding the Dependent Variable"]},{"cell_type":"code","metadata":{"id":"XgHCShVyTOYY"},"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y = le.fit_transform(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyhY8-gPpFCa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273151948,"user_tz":360,"elapsed":2,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"6e3980da-c905-4f5c-dd03-cbcab119a5a7"},"source":["print(y)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"qb_vcgm3qZKW"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","metadata":{"id":"pXgA6CzlqbCl"},"source":["from sklearn.model_selection import train_test_split\n","\n","# Training set must contain most of the data (test_size = 20% of the data)\n","# random_state is a seed to guarantee that the data splitting is indeed reproducible, this prevents variations in the model performance\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuwQhFdKrYTM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273154490,"user_tz":360,"elapsed":126,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"51d61ab6-9b4e-4ccb-c3bf-73f33077eb4c"},"source":["print(X_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}]},{"cell_type":"code","metadata":{"id":"TUrX_Tvcrbi4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273155407,"user_tz":360,"elapsed":2,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"2699c97a-ce98-4ed2-e92c-1650b81d847b"},"source":["print(X_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}]},{"cell_type":"code","metadata":{"id":"pSMHiIsWreQY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273156422,"user_tz":360,"elapsed":135,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"9e38ac8c-3722-44a9-8e96-1e04daaaed2a"},"source":["print(y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 0 0 1 1 0 1]\n"]}]},{"cell_type":"code","metadata":{"id":"I_tW7H56rgtW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273157075,"user_tz":360,"elapsed":1,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"cb2be589-c965-4527-c225-a96eec8f6d0d"},"source":["print(y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TpGqbS4TqkIR"},"source":["## Feature Scaling"]},{"cell_type":"code","metadata":{"id":"AxjSUXFQqo-3"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","# Feature Scaling: Use normalisation when your data follows normal distribution\n","# However Standarisation works well for almost all situations\n","\n","# Standard Scaling prevents some features to be dominating\n","# NOTE: In this case we are not Standardising the dummy variables for the countries encoding\n","sc = StandardScaler()\n","X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n","X_test[:, 3:] = sc.transform(X_test[:, 3:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWPET8ZdlMnu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273227079,"user_tz":360,"elapsed":138,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"d2f75d1b-24ca-43b2-98e4-b15868484c25"},"source":["print(X_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"]}]},{"cell_type":"code","metadata":{"id":"sTXykB_QlRjE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724273228824,"user_tz":360,"elapsed":2,"user":{"displayName":"TGalg","userId":"02146590388002757982"}},"outputId":"9d1ce5a8-e3f0-4e1b-8026-338c0e531a4e"},"source":["print(X_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n"," [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"]}]}]}